{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverting the Formula for the Ising Coupling Matrix \n",
    "\n",
    "## Notes on Network Performance\n",
    "\n",
    "Trying to invert:\n",
    "\n",
    "\\begin{split}J_{i,j}&=\\sum^N_{n=1}\\Omega_{i,n}\\Omega_{j,n}\n",
    "  \\sum^N_{m=1}&\\frac{\\eta_{i,m}\\eta_{j,m}\\omega_{m}}{\\mu_{n}^2-\\omega_{m}^2}\n",
    "\\end{split}\n",
    "\n",
    "- where $\\Omega$ is the unknown set of parameters and we construct out data set by sampling values of $\\Omega$ from  $U(0,1)$ distribution.\n",
    "- so far we have been using a simple feedforward network with $J_{i,j}$ as the inputs\n",
    "- the sigmoid activation is used and we apply the tranformation $2x-1$ to the output of the last layer to obtain a prediction for $\\Omega$\n",
    "\n",
    "- We use cost function:\n",
    "\\begin{split}C_{x}&=\\frac{1}{2}\\sum_{j}&(y_{j}-(2a_{j}^{L}-1))^2\n",
    "\\end{split}\n",
    "where L is the output layer and the sum is over all j in the outputlayer and $a^{l}_{i}$ denotes the activation of the $i$-th neuron in the $l$-th later.\n",
    "\n",
    "Test Results:\n",
    "\n",
    "- We have tested data corresponding to ionchains of size N=3 to 11. \n",
    "- The data sets we use are of size appears to have little impact although we use 100,000 data pairs split 60/20/20 into training set, validation set and test set.\n",
    "- aside from N=10, we got that on an untrained network $\\frac{Cost of test data}{Number of Outputs} \\approx 0.26$ and once training had been completed $\\frac{Cost of test data}{Number of Outputs} \\approx 0.17$ so something was learned although the $J_{i,j}$ predictions resulting from the $\\Omega$ predictions dont appear helpful \n",
    "\n",
    "\n",
    "\n",
    "Observations:\n",
    "\n",
    "- most of the training is done on the first epoch\n",
    "- $J_{i,j}$ depends only on the $i$-th and $j$-th rows of $\\Omega$ and so it seems that some of the connections in the network may be unhelpful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ionchain\n",
    "import classes\n",
    "import pickle\n",
    "import numpy as np\n",
    "import network\n",
    "import network2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing\n",
    "% matplotlib inline\n",
    "\n",
    "ionchain3 = ionchain.IonChain(3,[5,1])\n",
    "ionchain4 = ionchain.IonChain(4,[5,1])\n",
    "ionchain5 = ionchain.IonChain(5,[5,1])\n",
    "ionchain6 = ionchain.IonChain(6,[5,1])\n",
    "ionchain10 = ionchain.IonChain(10,[5,1])\n",
    "ionchain7 = ionchain.IonChain(7,[5,1])\n",
    "ionchain8 = ionchain.IonChain(8,[5,1])\n",
    "ionchain9 = ionchain.IonChain(9,[5,1])\n",
    "ionchain11 = ionchain.IonChain(11,[5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Model the Physical System\n",
    "These functions, Lambe_Dicke J_ij1 and J_ij used to make the necessary calculations to model an instance of an ion chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lamb_Dicke(ic):\n",
    "    \"\"\"Computes Lamb-Dicke parameters for a trapped ion chain \n",
    "    \n",
    "    Args:\n",
    "        ic (Object) - an instance of a trapped ion chain\n",
    "        \n",
    "    Returns:\n",
    "        An nxn matrix where n is the number of ions in the ion chain.\n",
    "        The i,mth entry of the matrix corresponds to the Lambe-Dicke\n",
    "        parameter eta[i,m] which sets the scale for the coupling between\n",
    "        spin i and mode m.\n",
    "    \"\"\"\n",
    "    deltak = 2*1.7699*10**7\n",
    "    M = 2.8395 * 10**(-25)\n",
    "    hbar = 1.0546e-34\n",
    "    n = ic.n\n",
    "    b_ij = ic.x_eigvecs\n",
    "    omega_m = ic.x_freqs\n",
    "    eta = np.empty([n,n])\n",
    "    for m in range(n):\n",
    "        for i in range(n):\n",
    "            eta[i,m] = b_ij[i,m]*deltak*((hbar/(2*M*omega_m[m]))**0.5)\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J_ij1(mu, Rabi_freq, ic):\n",
    "    \"\"\"Computes spin-spin coupling beteen atoms in a trapped ion\n",
    "    chain with global beatnote detuning. \n",
    "    \n",
    "    Args:\n",
    "        mu(float) - global beatnote detuning parameter\n",
    "        ic (Object) - an instance of a trapped ion chain\n",
    "        Rabi_freq(An 1Xn vector of floats, where n is number of ions\n",
    "        in the chain) \n",
    "            - containing where the ith entry is the single spin Rabi\n",
    "            frequency of atom i\n",
    "        \n",
    "    Returns:\n",
    "        An nxn matrix where n is the number of ions in the ion chain.\n",
    "        The i,jth is the spin-spin coupling beteen atoms i and j in the\n",
    "        ion chain.\n",
    "    \"\"\"\n",
    "    n = ic.n\n",
    "    eta = Lamb_Dicke(ic)\n",
    "    omega_m = ic.x_freqs\n",
    "    J = np.empty((n,n))\n",
    "    for i in range(n):\n",
    "        J[i,i] = 0\n",
    "        for j in range(i+1,n):\n",
    "            J[i,j] = Rabi_freq[i]*Rabi_freq[j]* np.sum(eta[i, :] * eta[j, :] * omega_m[:] /(np.full((1,n),mu)**2 - omega_m[:]**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_2(matrix):\n",
    "    return np.linalg.norm(matrix)\n",
    "def L_1(matrix):\n",
    "    return np.sum(np.abs(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J_ij(mus, Rabi_freq_matrix, ic, norm_function):\n",
    "    n = ic.n\n",
    "    eta = Lamb_Dicke(ic)\n",
    "    omega_m = ic.x_freqs\n",
    "    F = np.empty((n, n, len(mus)))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for m in range(len(mus)):\n",
    "                F[i, j, m] = np.sum(eta[i, :] * eta[j, :] * omega_m[:] /\n",
    "                                    (mus[m]**2 - omega_m[:]**2))\n",
    "    J = np.empty((n, n))\n",
    "    for i in range(n):\n",
    "        J[i, i] = 0\n",
    "        for j in range(i + 1, n):\n",
    "            J[i, j] = np.sum(Rabi_freq_matrix[i, :] * Rabi_freq_matrix[j, :] * F[i, j, :])\n",
    "            J[j, i] = J[i, j]\n",
    "            \n",
    "    upper_triangular = J[np.triu_indices(n,1)]\n",
    "    size_upper = int(n*(n-1)/2)\n",
    "    norm = norm_function(upper_triangular)\n",
    "    if norm != 0:\n",
    "        normalized_J = J/norm\n",
    "        normalized_upper_triangular = upper_triangular/norm\n",
    "    else:\n",
    "        normalized_J = J\n",
    "        normalized_upper_triangular = upper_triangular\n",
    " \n",
    "    J_dict = {'original' : J, \n",
    "              'upper triangular' : np.reshape(upper_triangular, (size_upper,1)),\n",
    "              'norm' : norm,\n",
    "              'normalized' : normalized_J,\n",
    "              'normailzed upper triangular' : np.reshape(normalized_upper_triangular, (size_upper,1))}\n",
    "\n",
    "    return J_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Data\n",
    "The functions mu_calculator, data_creator and create_data_file are all used to generate synthetic data. normalize is used to standardize the J_ij inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_calculator(ic):\n",
    "    \"\"\"Given an ionchain as input will calculate a beatnote detuning vector\n",
    "    based on the transverse mode frequencies.\"\"\"\n",
    "    n = ic.n\n",
    "    omega_m = ic.x_freqs\n",
    "    mu = []\n",
    "    for i in range(n-1):\n",
    "        #alter the following line to change location of ith beatnote\n",
    "        #detuning wrt to ith and i+1th transverse mode frequency\n",
    "        mu_i = omega_m[i] + (omega_m[i+1]-omega_m[i])*0.1\n",
    "        mu.append(mu_i)\n",
    "    mu.append(omega_m[-1]*1.01)\n",
    "    return mu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    " def data_creator(ic, data_size, norm_function):\n",
    "    \"\"\"Generates data for a particular ion chain ic.\n",
    "    The data is returned in the form of a list of tuples.\n",
    "    eg. [(x0,y0),(x1,y1),...] where (xi,yi) corresponds to an input output\n",
    "    pair when it comes time to train the network. xi corresponds to the\n",
    "    J_ijs and yi the Rabi_frquencies for the network.\n",
    "    \n",
    "    Note the xi and yis will be numpy vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    ic(Object from IonChain Class) - the ion chain from which to construct\n",
    "    data from\n",
    "    \n",
    "    data_size(Int) - desired data size\n",
    "    \n",
    "    \"\"\"\n",
    "    n = ic.n\n",
    "    omega_m = ic.x_freqs\n",
    "    #Note: this function assumes that mu(beatnote detunings) are\n",
    "    #predetermined and are calculated using the following line of code.\n",
    "    #This function can be easily modified to change this.\n",
    "    mu = mu_calculator(ic)\n",
    "    #create dictionary to store information later\n",
    "    d = {}\n",
    "    #create list to store data later\n",
    "    data = []\n",
    "    for i in range (0, data_size):\n",
    "        #alter this line of code to get frquencies from another\n",
    "        #distribution\n",
    "        Rabi = np.random.uniform(low=-1, high=1, size=(n,n))\n",
    "        J_dict = J_ij(mu, Rabi, ic, norm_function)\n",
    "        y = np.reshape(Rabi,(n**2,1))\n",
    "        #alter this line of code so that input data is different\n",
    "        data.append((J_dict['normailzed upper triangular'],y))\n",
    "    d['data'] = data\n",
    "    d['ionchain'] = ic\n",
    "    d['data_size'] = data_size\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_file(filename, ic, data_size, norm_function):\n",
    "    \"\"\"Creates a pickled file containing synthetic test data.\n",
    "    Arguments:\n",
    "    filename(string)-desired filename\n",
    "    ic(Object from IonChain Class)-the ion chain from which to construct\n",
    "    data from\n",
    "    data_size(Int)-desired data size\n",
    "    triangular(Bool) - if only want the input data to be entries of J_ij\n",
    "    above the diagonal\"\"\"\n",
    "    d = data_creator(ic, data_size, norm_function)\n",
    "    data = d['data']\n",
    "    d['training_set'] = data[:int(len(data)*0.6)]\n",
    "    d['validation_set'] = data[int(len(data)*0.6) :int(len(data)*0.8)]\n",
    "    d['test_set'] = data[int(len(data)*0.8):]\n",
    "    f = open(filename, 'wb')\n",
    "    pickle.dump(d, f)\n",
    "    f.close()\n",
    "    \n",
    "#create_data_file('data_L1.pickle', ionchain3, 1000000, L_1)\n",
    "#create_data_file('data_ic4_L1.pickle', ionchain4, 100000, L_1)\n",
    "create_data_file('data_ic15_L1.pickle', ionchain15, 10000, L_1)\n",
    "d = pickle.load(open('data_ic15_L1.pickle', \"rb\"))\n",
    "net1 = network2.Network([105,500,225])\n",
    "net1.total_cost_no_reg(d['training_set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation\n",
    "The following code is used to define a create a neural network and its architecture, using a modified version of Micheal Nielsons network2.py file, then train it. After running this code the output will currently be the cost for the training and test data at the end of each epoch stored in an array. Along with a plot for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(filename,architecture,epochs,mini_batch,eta,lmbda=0,save=False,\n",
    "         save_name=None):\n",
    "    d = pickle.load(open(filename, \"rb\"))\n",
    "    ic = d['ionchain']\n",
    "    training_set = d['training_set']\n",
    "    validation_set = d['validation_set']\n",
    "    test_set = d['test_set']\n",
    "    net = network2.Network(architecture)\n",
    "    net.SGD(training_set, epochs, mini_batch, eta ,lmbda,\n",
    "        validation_set,eta_update=True)\n",
    "    if save:\n",
    "        if save_name:\n",
    "            d['sizes'] = architecture\n",
    "            d['weights'] = net.weights\n",
    "            d['biases'] = net.biases\n",
    "            d['cost'] = net.cost\n",
    "            f = open(save_name, 'wb')\n",
    "            pickle.dump(d, f)\n",
    "            f.close()    \n",
    "        else:\n",
    "            print ('Must specify filename, to argument save_name to save network to.')\n",
    "    return net.total_cost_no_reg(test_set)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train('data_ic15_L1.pickle'',[105,500,225],20,10,0.01,save=True,\n",
    "     save_name='data_L1_ic15_network_1.pickle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "The following code can be modified and used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison(J,filename):\n",
    "    \"\"\"Given an Ising coupling matrix J and a trained neural network \"\"\"\n",
    "    d = pickle.load(open(filename, \"rb\"))\n",
    "    ic = d['ionchain']\n",
    "    n = ic.n\n",
    "    input_size = int(n*(n-1)/2)\n",
    "    net = network2.Network(d['sizes'],d['cost'])\n",
    "    net.weights = d['weights']\n",
    "    net.biases = d['biases']\n",
    "    J_upper = J[np.triu_indices(n,1)]\n",
    "    norm = np.linalg.norm(J_upper)\n",
    "    if norm != 0:\n",
    "        J_normalized = J/norm\n",
    "        J_upper_normalized = np.reshape(J_upper/norm, (input_size,1))\n",
    "    else:\n",
    "        J_normalized = J\n",
    "        J_upper_normalized = np.reshape(J_upper, (input_size,1)) \n",
    "    #prints the normalized J so that it can be compared to the prediction\n",
    "    print (J_normalized)\n",
    "    nn_prediction = 2*net.feedforward(J_upper_normalized)-1\n",
    "    mu = mu_calculator(ic)\n",
    "    Rabi_approx = np.reshape(nn_prediction,(n,n))\n",
    "    J_approx = J_ij(mu, Rabi_approx, ic, L_1)\n",
    "    return J_approx['normalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison(np.array([[0,1,0],[1,0,1],[0,1,0]]),'data_L1_network_1.pickle')\n",
    "#comparison(np.array([[0,1,0,0,0],[1,0,1,0,0],[0,1,0,1,0],[0,0,1,0,1],[0,0,0,1,0]]),'data_L1_ic5_network_1.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
